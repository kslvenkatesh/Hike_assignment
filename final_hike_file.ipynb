{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/venkatesh.sl/Desktop/Hike_Hackthon'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import dask.dataframe as dd\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import os.path\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.chdir('//Users//venkatesh.sl//desktop//Hike_Hackthon')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_train_data = dd.read_csv(\"user_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_train_data_node1 = dd.read_csv(\"user_features.csv\", header=0,names = ['node1_id',\n",
    "'f1_n1',\n",
    "'f2_n1',\n",
    "'f3_n1',\n",
    "'f4_n1',\n",
    "'f5_n1',\n",
    "'f6_n1',\n",
    "'f7_n1',\n",
    "'f8_n1',\n",
    "'f9_n1',\n",
    "'f10_n1',\n",
    "'f11_n1',\n",
    "'f12_n1',\n",
    "'f13_n1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_train_data_node2 = dd.read_csv(\"user_features.csv\", header=0,names = ['node2_id',\n",
    "'f1_n2',\n",
    "'f2_n2',\n",
    "'f3_n2',\n",
    "'f4_n2',\n",
    "'f5_n2',\n",
    "'f6_n2',\n",
    "'f7_n2',\n",
    "'f8_n2',\n",
    "'f9_n2',\n",
    "'f10_n2',\n",
    "'f11_n2',\n",
    "'f12_n2',\n",
    "'f13_n2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n1=dd.merge(train_data, uf_train_data_node1, left_on='node1_id', right_on='node1_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n1_n2=dd.merge(train_n1, uf_train_data_node2, left_on='node2_id', right_on='node2_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = train_n1_n2.drop('node1_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x1.drop('node2_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample=train_data.head(1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_chat</th>\n",
       "      <th>f1_n1</th>\n",
       "      <th>f2_n1</th>\n",
       "      <th>f3_n1</th>\n",
       "      <th>f4_n1</th>\n",
       "      <th>f5_n1</th>\n",
       "      <th>f6_n1</th>\n",
       "      <th>f7_n1</th>\n",
       "      <th>f8_n1</th>\n",
       "      <th>f9_n1</th>\n",
       "      <th>...</th>\n",
       "      <th>f4_n2</th>\n",
       "      <th>f5_n2</th>\n",
       "      <th>f6_n2</th>\n",
       "      <th>f7_n2</th>\n",
       "      <th>f8_n2</th>\n",
       "      <th>f9_n2</th>\n",
       "      <th>f10_n2</th>\n",
       "      <th>f11_n2</th>\n",
       "      <th>f12_n2</th>\n",
       "      <th>f13_n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_chat  f1_n1  f2_n1  f3_n1  f4_n1  f5_n1  f6_n1  f7_n1  f8_n1  f9_n1  \\\n",
       "0        0     31      6      0     31      7      0     31      8      1   \n",
       "1        0      0      0      0      3      2      0      9      3      0   \n",
       "2        0     27     25      3     27     24      3     28     23      3   \n",
       "3        1      1      1      1      5      5      5     11     11     11   \n",
       "4        0     31     15      8     31     15      9     31     13      8   \n",
       "\n",
       "   ...  f4_n2  f5_n2  f6_n2  f7_n2  f8_n2  f9_n2  f10_n2  f11_n2  f12_n2  \\\n",
       "0  ...     31     30     11     31     30     17      31      31      24   \n",
       "1  ...     31     30     11     31     30     17      31      31      24   \n",
       "2  ...     31     30     11     31     30     17      31      31      24   \n",
       "3  ...     31     30     11     31     30     17      31      31      24   \n",
       "4  ...     31     30     11     31     30     17      31      31      24   \n",
       "\n",
       "   f13_n2  \n",
       "0       7  \n",
       "1       7  \n",
       "2       7  \n",
       "3       7  \n",
       "4       7  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test_train_split from sklearn library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = train_sample.drop('is_chat',axis=1)\n",
    "# Putting response variable to y\n",
    "y = train_sample['is_chat']\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99    438106\n",
      "           1       0.00      0.00      0.00     11894\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    450000\n",
      "   macro avg       0.49      0.50      0.49    450000\n",
      "weighted avg       0.95      0.97      0.96    450000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438106      0]\n",
      " [ 11894      0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735688888888889\n"
     ]
    }
   ],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n1=dd.merge(test_data, uf_train_data_node1, left_on='node1_id', right_on='node1_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n1_n2=dd.merge(test_n1, uf_train_data_node2, left_on='node2_id', right_on='node2_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = test_n1_n2.drop('node1_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = x_test1.drop('node2_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features1 = test_features.drop('id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1_n1', 'f2_n1', 'f3_n1', 'f4_n1', 'f5_n1', 'f6_n1', 'f7_n1', 'f8_n1',\n",
       "       'f9_n1', 'f10_n1', 'f11_n1', 'f12_n1', 'f13_n1', 'f1_n2', 'f2_n2',\n",
       "       'f3_n2', 'f4_n2', 'f5_n2', 'f6_n2', 'f7_n2', 'f8_n2', 'f9_n2', 'f10_n2',\n",
       "       'f11_n2', 'f12_n2', 'f13_n2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = rfc.predict(test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing predections to file \n",
    "prediction = pd.DataFrame(predictions, columns=['is_chat']).to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.read_csv(\"prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['id'] = prediction.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction[['id', 'is_chat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"prediction_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
